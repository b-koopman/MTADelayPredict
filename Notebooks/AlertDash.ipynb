{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative MTADelayPredict Project\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.realpath(os.path.join('DataExploration.ipynb')))))\n",
    "from MTADelayPredict.utils import gtfs_loader, stop_info\n",
    "from MTADelayPredict.subway_line import SubwayLine, N_STOP_LIST\n",
    "from MTADelayPredict.stop import Stop\n",
    "from importlib import reload\n",
    "from MTADelayPredict.plotting import alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "subway_line = SubwayLine(N_STOP_LIST)\n",
    "obs_stop = subway_line.stop('R16N')\n",
    "\n",
    "def stop_processor(name):\n",
    "    name = str(name)\n",
    "    if str.lower(name) == 'nan':\n",
    "        return ''\n",
    "    \n",
    "    # Strip parenthesis borough delimeters, we know what line we're on\n",
    "    stop_ids = stop_info.name2stop_ids(name, N_STOP_LIST)\n",
    "    \n",
    "    # If there were issues parsing, check a few things\n",
    "    if len(stop_ids) == 0:\n",
    "        # Is this a range? \n",
    "        range_m = re.match(r'^(.+),(.+)', name)\n",
    "        if range_m:\n",
    "            stop_1 = subway_line.stop(stop_info.name2stop_ids(range_m.groups()[0], N_STOP_LIST).iloc[0])\n",
    "            stop_2 = subway_line.stop(stop_info.name2stop_ids(range_m.groups()[1], N_STOP_LIST).iloc[0])\n",
    "            \n",
    "            if abs(stop_1.stop_idx - obs_stop.stop_idx) < abs(stop_2.stop_idx - obs_stop.stop_idx):\n",
    "                return stop_1.stop_id\n",
    "            else:\n",
    "                return stop_2.stop_id\n",
    "            \n",
    "        # Still unparsable\n",
    "        return name\n",
    "        \n",
    "    return stop_ids.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "alert_dir = '../data/raw/alerts'\n",
    "annotated_alert_df = pd.read_csv(os.path.abspath(os.path.join(alert_dir, 'nqrw_alerts.csv')))\n",
    "\n",
    "n_alert_df = annotated_alert_df[annotated_alert_df['Direction'] == 'Northbound']\n",
    "n_alert_df['IssueStopID'] = n_alert_df['IssueStop'].map(stop_processor)\n",
    "n_alert_df = n_alert_df.reset_index()\n",
    "n_alert_df = n_alert_df.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "weekday_dict = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "\n",
    "def create_mta_wait(feature_df, alert_stop, observing_stop, date, start_time, end_time, stop_id, feature, transform):\n",
    "\n",
    "    traces = []\n",
    "#     next_scheduled_df = data['next_scheduled_arrival']\n",
    "#     schedule_df = data['schedule_df']\n",
    "    \n",
    "    ##### Set up MTA predicted arrival time ############\n",
    "#     OBSERVED_STOP = 'R16N'\n",
    "#     mta_predicted = next_scheduled_df[OBSERVED_STOP].map(lambda x: pd.to_datetime(x, unit='m', utc=True).tz_convert('US/Eastern')).to_frame()\n",
    "#     mta_predicted = mta_predicted.resample('1T').min()\n",
    "#     mta_predicted['time'] = mta_predicted.index.shift(-1)\n",
    "\n",
    "#     mta_predicted['wait'] = (mta_predicted[OBSERVED_STOP] - mta_predicted['time'])\n",
    "#     mta_predicted['wait'] = mta_predicted['wait'].map(lambda x: x.delta// 60000000000 if isinstance(x, pd.Timedelta) else x)\n",
    "#     mta_predicted.dropna(how='any', inplace=True)\n",
    "    \n",
    "#     subway_line = SubwayLine(N_STOP_LIST)\n",
    "    \n",
    "#     t = go.Scatter(x=mta_predicted['time'],\n",
    "#                    y=mta_predicted['wait'],\n",
    "#                    mode='lines+markers',\n",
    "#                    name='MTA Predicted Wait',\n",
    "#                    x0=schedule_df['index'].iloc[0]\n",
    "#                   )\n",
    "#     traces.append(t)\n",
    "    \n",
    "    ###### Plot different features ######\n",
    "\n",
    "    feature_df.index = feature_df.index.map(lambda x: x.tz_localize('UTC').tz_convert('US/Eastern'))\n",
    "    \n",
    "#    print(feature_df)\n",
    "#    print((feature, transform, stop_id))\n",
    "    \n",
    "    t = go.Scatter(x=feature_df.index,\n",
    "                   y=feature_df.loc[:, (feature, transform, stop_id)],\n",
    "                   mode='lines+markers',\n",
    "                   name='feature:{} transform: {} stop: {}'.format(feature, transform, stop_info.stop_id2name(observing_stop)),\n",
    "                   x0=start_time\n",
    "                  )\n",
    "    traces.append(t)    \n",
    "\n",
    "#     t = go.Scatter(x=min_since_train.index,\n",
    "#                    y=min_since_train,\n",
    "#                    mode='lines+markers',\n",
    "#                    name='{} min_since_train'.format(stop_info.stop_id2name(observing_stop)),\n",
    "#                    x0=schedule_df['index'].iloc[0]\n",
    "#                   )\n",
    "#     traces.append(t)\n",
    "    \n",
    "    shapes = list()\n",
    "\n",
    "    # Alert time\n",
    "    shapes.append({'type': 'line',\n",
    "                   'xref': 'x',\n",
    "                   'yref': 'y',\n",
    "                   'x0': date,\n",
    "                   'x1': date,\n",
    "                   'line_color': 'red'\n",
    "                  })\n",
    "\n",
    "    layout = go.Layout(\n",
    "                title= ('Feature {} Transform {} Stop {}'.format(feature, transform, stop_info.stop_id2name(stop_id))),\n",
    "                titlefont=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=15,\n",
    "                color='#7f7f7f'\n",
    "                ),\n",
    "                paper_bgcolor='rgba(0,0,0,0)',\n",
    "                plot_bgcolor='rgba(0,0,0,0)',\n",
    "                width=1500,\n",
    "                height=500,\n",
    "                margin={'l':200},\n",
    "\n",
    "                xaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "#                    tickvals = schedule_df['index'],\n",
    "#                    ticktext = schedule_df['index'],\n",
    "                    title='Time'\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "                    title='Minutes',\n",
    "                ),\n",
    "                shapes=shapes\n",
    "    )\n",
    "    return {'data':traces, 'layout':layout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "weekday_dict = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "\n",
    "def create_schedules(schedule_df, alert_stop, observing_stop, date, start_time, end_time):\n",
    "    traces = []\n",
    "    \n",
    "    subway_line = SubwayLine(N_STOP_LIST)\n",
    "\n",
    "    schedule_df['index'] = schedule_df['index'].map(lambda x: pd.to_datetime(x, unit='ms', utc=True).tz_convert('US/Eastern'))\n",
    "    schedule_df[schedule_df['index'] > start_time]\n",
    "    \n",
    " #   print(schedule_df)\n",
    "    \n",
    "    for col in schedule_df.columns[2:]:\n",
    "        plot_df = schedule_df[['index', col]].dropna()\n",
    "        if (plot_df.shape[0] == 0 or plot_df['index'].iloc[-1] < start_time) or (plot_df['index'].iloc[0] > end_time):\n",
    "            continue\n",
    "\n",
    "        t = go.Scatter(\n",
    "                    x= plot_df['index'],\n",
    "                    y = plot_df[col],\n",
    "                    mode='lines+markers',\n",
    "                    name=col,\n",
    "                    x0=schedule_df['index'].iloc[0],\n",
    "                    showlegend=False\n",
    "            )\n",
    "\n",
    "        traces.append(t)\n",
    "    shapes = list()\n",
    "\n",
    "    # Alert time\n",
    "    shapes.append({'type': 'line',\n",
    "                   'xref': 'x',\n",
    "                   'yref': 'y',\n",
    "                   'x0': date,\n",
    "                   'x1': date,\n",
    "                   'y0': 0,\n",
    "                   'y1': schedule_df.iloc[:, 2:].max().max(),\n",
    "                   'line_color': 'red'\n",
    "                  })\n",
    "\n",
    "    # Alert stop\n",
    "    shapes.append({'type': 'line',\n",
    "                   'xref': 'x',\n",
    "                   'yref': 'y',\n",
    "                   'x0': schedule_df['index'].min(),\n",
    "                   'x1': schedule_df['index'].max(),\n",
    "                   'y0': subway_line.stop_idx(alert_stop),\n",
    "                   'y1': subway_line.stop_idx(alert_stop),\n",
    "                   'line_color': 'red'\n",
    "                  })\n",
    "\n",
    "    # Observed stop\n",
    "    shapes.append({'type': 'line',\n",
    "                   'xref': 'x',\n",
    "                   'yref': 'y',\n",
    "                   'x0': schedule_df['index'].min(),\n",
    "                   'x1': schedule_df['index'].max(),\n",
    "                   'y0': subway_line.stop_idx(observing_stop),\n",
    "                   'y1': subway_line.stop_idx(observing_stop),\n",
    "                   'line_color': 'green'\n",
    "                  })\n",
    "\n",
    "    layout = go.Layout(\n",
    "                title= ('Alert @ {} {}'.format(date, weekday_dict[date.dayofweek])),\n",
    "                titlefont=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=15,\n",
    "                color='#7f7f7f'\n",
    "                ),\n",
    "                paper_bgcolor='rgba(0,0,0,0)',\n",
    "                plot_bgcolor='rgba(0,0,0,0)',\n",
    "                width=1600,\n",
    "                height=800,\n",
    "                margin={'l':200},\n",
    "\n",
    "                xaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "                    tickvals = schedule_df['index'],\n",
    "                    ticktext = schedule_df['index'],\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "                    tickvals = [i for i,_ in enumerate(N_STOP_LIST)],\n",
    "                    ticktext = [stop_info.stop_id2name(s) for s in N_STOP_LIST],\n",
    "                    title='Stop',\n",
    "                ),\n",
    "                shapes=shapes\n",
    "    )\n",
    "    return {'data':traces, 'layout':layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(df):\n",
    "    features = []\n",
    "    features.append(df)\n",
    "    features.append(df.rolling('5T').max())\n",
    "    features.append(df.rolling('15T').max())\n",
    "    features.append(df.rolling('30T').max())\n",
    "    features.append(df.rolling('45T').max())\n",
    "    features.append(df.rolling('60T').max())\n",
    "    features.append(df.rolling('90T').max())\n",
    "    return pd.concat(features, axis=1, keys=['minutes', 'max5', 'max15', 'max30', 'max45', 'max60', 'max90'], names=['transform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Running on http://0.0.0.0:8050/\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      "Debugger PIN: 376-798-318\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25552526\n",
      "25552646\n",
      "2555252625552526\n",
      "25552646\n",
      "\n",
      "25552646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                     |entries: ------decode_errors: ------Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "  6%|##                                   |entries: ------decode_errors: ------Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25552526\n",
      "25552646\n",
      "25552526\n",
      "25552646\n",
      "25552526\n",
      "25552646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|####                                 |entries: ------decode_errors:      1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2018-08-01 11:26:00-04:00 - 2018-08-01 15:26:00-04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:      5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n",
      "Loading 2018-08-01 11:26:00-04:00 - 2018-08-01 15:26:00-04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25565873\n",
      "25565993\n",
      "25565873\n",
      "25565993\n",
      "25565873\n",
      "25565993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n",
      "\n",
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n",
      "New stops:\n",
      "set()\n",
      "New stops:\n",
      "set()\n",
      "Loading 2018-08-10 17:53:00-04:00 - 2018-08-10 21:53:00-04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25565873\n",
      "25565993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|############################         |entries: ------decode_errors: ------Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25565873\n",
      "25565993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25574346\n",
      "25574466\n",
      "25574346\n",
      "25574466\n",
      "25574346\n",
      "25574466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:     15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors:     15\n",
      "100%|#####################################|entries: ------decode_errors:     15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n",
      "New stops:\n",
      "set()\n",
      "Loading 2018-08-16 15:06:00-04:00 - 2018-08-16 19:06:00-04:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n",
      "Exception possibly due to cache backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 795, in decorated_function\n",
      "    f, *args, **kwargs\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 592, in make_cache_key\n",
      "    f, args=args, timeout=_timeout, forced_update=forced_update\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 543, in _memoize_version\n",
      "    version_data_list = list(self.cache.get_many(*fetch_keys))\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/flask_caching/__init__.py\", line 239, in cache\n",
      "    return app.extensions[\"cache\"][self]\n",
      "KeyError: 'cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25589693\n",
      "25589813\n",
      "25589693\n",
      "25589813\n",
      "25589693\n",
      "25589813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#####################################|entries: ------decode_errors: ------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stops:\n",
      "set()\n",
      "Loading 2018-08-27 06:53:00-04:00 - 2018-08-27 10:53:00-04:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash_table\n",
    "import re\n",
    "from dash.exceptions import PreventUpdate\n",
    "from plotly.subplots import make_subplots\n",
    "from flask import Flask\n",
    "from flask_caching import Cache\n",
    "import redis\n",
    "\n",
    "external_stylesheets = [    # Dash CSS\n",
    "    'https://codepen.io/chriddyp/pen/bWLwgP.css',\n",
    "    # Loading screen CSS\n",
    "    'https://codepen.io/chriddyp/pen/brPBPO.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "CACHE_CONFIG = {\n",
    "    # try 'filesystem' if you don't want to setup redis\n",
    "    'CACHE_TYPE': 'redis',\n",
    "    'CACHE_REDIS_URL': os.environ.get('REDIS_URL', 'redis://localhost:6379')\n",
    "}\n",
    "cache = Cache()\n",
    "cache.init_app(app.server, config=CACHE_CONFIG)\n",
    "\n",
    "transforms = ['minutes', 'max5', 'max15', 'max30', 'max45', 'max60', 'max90']\n",
    "features = ['min_in_station', 'min_since_train']\n",
    "stop_ids = N_STOP_LIST\n",
    "\n",
    "transform_dropdown = [{'label':x, 'value':x} for x in transforms ]\n",
    "feature_dropdown = [{'label':x, 'value':x} for x in features ]\n",
    "stop_dropdown = [{'label':stop_info.stop_id2name(x), 'value':x} for x in stop_ids]\n",
    "\n",
    "\n",
    "dropdown_values = []\n",
    "for idx,row in n_alert_df.iterrows():\n",
    "    dropdown_values.append({'label':\"{} {}\".format(row.Date, row.Subject), 'value': idx})\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "app.layout = html.Div([\n",
    "    dcc.DatePickerSingle(\n",
    "        id='my-date-picker-single',\n",
    "        min_date_allowed=dt(1995, 8, 5),\n",
    "        max_date_allowed=dt(2017, 9, 19),\n",
    "        initial_visible_month=dt(2017, 8, 5),\n",
    "        date=str(dt(2017, 8, 25, 23, 59, 59))\n",
    "    ),\n",
    "#    html.Button('Previous', id='prev-button', n_clicks=0),\n",
    "#    html.Button('Next', id='next-button', n_clicks=0),\n",
    "    dcc.Dropdown(\n",
    "        id='alert-dropdown',\n",
    "        options=dropdown_values,\n",
    "        value=1\n",
    "    ),\n",
    "    html.Div(id='current-alert'),\n",
    "    html.Div(id='alert-subject'),\n",
    "    html.Div(id='alert-location'),\n",
    "    html.Div(id='alert-message'),\n",
    "    dcc.Graph(id='alert-graph'),\n",
    "    dcc.Graph(id='features-graph'),\n",
    "    dcc.Dropdown(\n",
    "        id='transform-dropdown',\n",
    "        options=transform_dropdown,\n",
    "        value=transforms[0]\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='feature-dropdown',\n",
    "        options=feature_dropdown,\n",
    "        value=features[0]\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='stop-dropdown',\n",
    "        options=stop_dropdown,\n",
    "        value=stop_ids[0]\n",
    "    ),\n",
    "    dcc.Graph(id='wait-graph'),\n",
    "    # Hidden div to keep track of what idx we're on\n",
    "    html.Div(id='schedule-df', style={'display': 'none'}),\n",
    "    html.Div(id='features-df', style={'display': 'none'}),\n",
    "])\n",
    "\n",
    "@app.callback(Output('wait-graph', 'figure'),\n",
    "             [Input('alert-dropdown', 'value')])\n",
    "def update_wait(idx):\n",
    "    schedule_df, feature_df = update_data(idx)\n",
    "    \n",
    "    WAIT_THRESHOLD = 15\n",
    "    OBSERVED_STOP = 'R16N'\n",
    "    traces = []\n",
    "\n",
    "    feature_df.index = feature_df.index.map(lambda x: x.tz_localize('UTC').tz_convert('US/Eastern'))\n",
    "\n",
    "    t = go.Scatter(x=feature_df.index,\n",
    "                   y=feature_df.loc[:, ('min_since_train', 'minutes', OBSERVED_STOP)],\n",
    "                   mode='lines+markers',\n",
    "                   name='wait_time @ {}'.format(stop_info.stop_id2name(OBSERVED_STOP)),\n",
    "                  )\n",
    "    traces.append(t)    \n",
    "    \n",
    "\n",
    "    predicted_value = feature_df.loc[:, ('min_since_train', 'minutes', OBSERVED_STOP)].fillna(method='ffill')\n",
    "    predicted_value = predicted_value.rolling('15T').max().shift(-15)\n",
    "    predicted_value[predicted_value < WAIT_THRESHOLD] = 0\n",
    "    predicted_value[predicted_value >= WAIT_THRESHOLD] = 1\n",
    "    \n",
    "#     t = go.Scatter(x=predicted_value.index,\n",
    "#                    y=predicted_value,\n",
    "#                    mode='lines+markers',\n",
    "#                    name='is_delay @ {}'.format(stop_info.stop_id2name(OBSERVED_STOP)),\n",
    "#                   )\n",
    "    t = go.Bar(x=predicted_value.index,\n",
    "                   y=predicted_value,\n",
    "                   name='is_delay @ {}'.format(stop_info.stop_id2name(OBSERVED_STOP)),\n",
    "                   marker_line_width=1.5, opacity=0.6,\n",
    "                  )\n",
    "    traces.append(t) \n",
    "    \n",
    "    shapes = list()\n",
    "\n",
    "    # Alert time\n",
    "    shapes.append({'type': 'line',\n",
    "                   'xref': 'x',\n",
    "                   'yref': 'y',\n",
    "                   'x0': feature_df.index[0],\n",
    "                   'x1': feature_df.index[-1],\n",
    "                   'y0': WAIT_THRESHOLD,\n",
    "                   'y1': WAIT_THRESHOLD,\n",
    "                   'line_color': 'red'\n",
    "                  })\n",
    "    \n",
    "    \n",
    "    layout = go.Layout(\n",
    "                title= ('Train Wait @ {}'.format(stop_info.stop_id2name(OBSERVED_STOP))),\n",
    "                titlefont=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=15,\n",
    "                color='#7f7f7f'\n",
    "                ),\n",
    "                paper_bgcolor='rgba(0,0,0,0)',\n",
    "                plot_bgcolor='rgba(0,0,0,0)',\n",
    "                width=1600,\n",
    "                height=800,\n",
    "                margin={'l':200},\n",
    "\n",
    "                xaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "                    tickvals = schedule_df['index'],\n",
    "                    ticktext = schedule_df['index'],\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    tickmode = 'array',\n",
    "                    title='minutes',\n",
    "                ),\n",
    "                shapes=shapes\n",
    "    )    \n",
    "    \n",
    "    wait_fig = go.Figure(data=traces, layout=layout)\n",
    "    return wait_fig\n",
    "    \n",
    "@app.callback(Output('features-graph', 'figure'),\n",
    "             [Input('alert-dropdown', 'value'), Input('transform-dropdown', 'value'), Input('feature-dropdown', 'value'), Input('stop-dropdown', 'value')])\n",
    "def update_features(idx, transform, feature, stop_id):\n",
    "    schedule_df, feature_df = update_data(idx)\n",
    "    \n",
    "    start_window = 120\n",
    "    end_window = 120\n",
    "    OBSERVED_STOP = 'R16N'\n",
    "    row = n_alert_df.iloc[int(idx)]\n",
    "\n",
    "#    print(\"At index {} [{}]\".format(idx, row.IssueStopID))\n",
    "#    print(row)\n",
    "    alert_time = pd.Timestamp(row.Date).tz_localize(\"US/Eastern\")\n",
    "    alert_stop = row.IssueStopID\n",
    "    if alert_stop == '':\n",
    "        alert_stop = 'R16N'\n",
    "\n",
    "    STOP_FILTER = '^.*N$'\n",
    "    ROUTE_FILTER = 'N'\n",
    "    data_dir = '../data/raw/status'\n",
    "\n",
    "    start_time = alert_time - pd.Timedelta(start_window, unit='m')\n",
    "    end_time = alert_time + pd.Timedelta(end_window, unit='m')\n",
    "    \n",
    "    schedule_dict =  create_schedules(schedule_df, alert_stop, OBSERVED_STOP, alert_time, start_time, end_time)\n",
    "    \n",
    "    \n",
    "    mta_wait_dict = create_mta_wait(feature_df, alert_stop, OBSERVED_STOP, alert_time, start_time, end_time, feature=feature, transform=transform, stop_id=stop_id)\n",
    "    \n",
    "    feature_fig = go.Figure(mta_wait_dict)\n",
    "    feature_fig.update_xaxes(schedule_dict['layout']['xaxis'])\n",
    "    return feature_fig\n",
    "\n",
    "@app.callback(\n",
    "    [Output('alert-subject', 'children'), Output('alert-location', 'children'), Output('alert-message', 'children')],\n",
    "[Input('alert-dropdown', 'value')])\n",
    "def display_alert(alert_idx):\n",
    "    row = n_alert_df.iloc[int(alert_idx)]\n",
    "    return 'Subject: '+row['Subject'], 'IssueStopID: '+ stop_info.stop_id2name(row['IssueStopID']), 'Message: '+row['Message']\n",
    "    \n",
    "@app.callback(\n",
    "    Output('current-alert', 'children'),\n",
    "    [Input('alert-dropdown', 'value')])\n",
    "def update_output(alert_idx):\n",
    "    string_prefix = 'You have selected: '    \n",
    "    row = n_alert_df.iloc[int(alert_idx)]\n",
    "\n",
    "    date = row.Date\n",
    "    if date is not None:\n",
    "        date = pd.Timestamp(str(date))\n",
    "        return string_prefix + str(date)\n",
    "    \n",
    "\n",
    "def update_data(idx):\n",
    "    @cache.memoize()\n",
    "    def query_and_serialize_data(idx):\n",
    "        start_window = 120\n",
    "        end_window = 120\n",
    "        OBSERVED_STOP = 'R16N'\n",
    "        row = n_alert_df.iloc[int(idx)]\n",
    "\n",
    "    #    print(\"At index {} [{}]\".format(idx, row.IssueStopID))\n",
    "    #    print(row)\n",
    "        alert_time = pd.Timestamp(row.Date).tz_localize(\"US/Eastern\")\n",
    "        alert_stop = row.IssueStopID\n",
    "        if alert_stop == '':\n",
    "            alert_stop = 'R16N'\n",
    "\n",
    "        STOP_FILTER = '^.*N$'\n",
    "        ROUTE_FILTER = 'N'\n",
    "        data_dir = '../data/raw/status'\n",
    "\n",
    "        start_time = alert_time - pd.Timedelta(start_window, unit='m')\n",
    "        end_time = alert_time + pd.Timedelta(end_window, unit='m')\n",
    "\n",
    "        # Fetch schedule data and plot\n",
    "        data = alerts.load_range_schedule(start_time, end_time, STOP_FILTER, ROUTE_FILTER, data_dir)\n",
    "\n",
    "        loader = data['loader']\n",
    "        schedule_dfs = []\n",
    "        for stop, train in zip(loader.stop_dict.items(), loader.train_dict.items()):\n",
    "            schedule_dfs.append(pd.DataFrame(stop[1], index=train[1], columns=[stop[0]]))\n",
    "        line = SubwayLine(N_STOP_LIST)\n",
    "        df = pd.concat(schedule_dfs)\n",
    "        df = df.sort_index()[start_time:end_time]\n",
    "\n",
    "\n",
    "        df = df.stack().reset_index()\n",
    "        df.columns = ['time', 'train_id', 'stop_id']\n",
    "        df = df.pivot_table(index='time', columns='stop_id', values='train_id', aggfunc=np.max)\n",
    "        df.sort_index(inplace=True)\n",
    "        df = df.resample('1T').last()\n",
    "\n",
    "        min_in_station = df.copy()\n",
    "        min_in_station[~df.isna()] = 1.0\n",
    "        min_in_station = min_in_station.astype(float)\n",
    "\n",
    "        train_gaps = df.copy().shift(1)\n",
    "        train_gaps[~df.isna()] = 0.0\n",
    "        train_gaps.fillna(method='ffill', inplace=True)\n",
    "        train_gaps.replace(0.0, np.nan, inplace=True)\n",
    "        min_since_train = train_gaps.copy()\n",
    "\n",
    "        min_since_train[~train_gaps.isna()] = 1.0\n",
    "        min_since_train = min_since_train.astype(float)\n",
    "\n",
    "        for observing_stop in df.columns:\n",
    "            min_since_train[observing_stop] = min_since_train[observing_stop].groupby(train_gaps[observing_stop]).cumsum()\n",
    "            min_in_station[observing_stop] = min_in_station[observing_stop].groupby(df[observing_stop]).cumsum()\n",
    "\n",
    "        min_in_station = build_features(min_in_station)\n",
    "        min_since_train = build_features(min_since_train)\n",
    "        features_df = pd.concat([min_in_station, min_since_train], axis=1, keys=['min_in_station', 'min_since_train'], names=['feature'])\n",
    "        \n",
    "        return [data['schedule_df'].to_json(), features_df.to_json()]\n",
    "    schedule_json, feature_json = query_and_serialize_data(idx)\n",
    "    feature_df = pd.read_json(feature_json)\n",
    "    \n",
    "    def str2tuple(s):\n",
    "        import re\n",
    "        foo = re.sub(r'[\\\"\\'\\(\\) ]', '', s)\n",
    "        return tuple(foo.split(','))\n",
    "        \n",
    "    feature_df.columns = pd.MultiIndex.from_tuples(feature_df.columns.map(str2tuple))\n",
    "#    print(feature_df.columns)\n",
    "#    feature_df.columns = pd.MultiIndex.from_tuples(feature_df.columns)\n",
    "    return [pd.read_json(schedule_json), feature_df]\n",
    "\n",
    "    \n",
    "    \n",
    "@app.callback(\n",
    "    Output('alert-graph', 'figure'),\n",
    "[Input('alert-dropdown', 'value')])\n",
    "def update_plot(idx):\n",
    "    start_window = 120\n",
    "    end_window = 120\n",
    "    OBSERVED_STOP = 'R16N'\n",
    "    row = n_alert_df.iloc[int(idx)]\n",
    "\n",
    "#    print(\"At index {} [{}]\".format(idx, row.IssueStopID))\n",
    "#    print(row)\n",
    "    alert_time = pd.Timestamp(row.Date).tz_localize(\"US/Eastern\")\n",
    "    alert_stop = row.IssueStopID\n",
    "    if alert_stop == '':\n",
    "        alert_stop = 'R16N'\n",
    "    \n",
    "    STOP_FILTER = '^.*N$'\n",
    "    ROUTE_FILTER = 'N'\n",
    "    data_dir = '../data/raw/status'\n",
    "    \n",
    "    start_time = alert_time - pd.Timedelta(start_window, unit='m')\n",
    "    end_time = alert_time + pd.Timedelta(end_window, unit='m')\n",
    "\n",
    "    schedule_df, feature_df = update_data(idx)\n",
    "    \n",
    "    print(\"Loading {} - {}\".format(start_time, end_time))\n",
    "    schedule_dict =  create_schedules(schedule_df, alert_stop, OBSERVED_STOP, alert_time, start_time, end_time)\n",
    "    \n",
    "    schedule_fig = go.Figure(schedule_dict)\n",
    "\n",
    "    return schedule_fig\n",
    "    \n",
    "#    fig = go.Figure()\n",
    "#    fig.show()\n",
    "#    return schedule_dict, mta_wait_dict\n",
    "    \n",
    "app.run_server(host='0.0.0.0', port='8050', debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
