{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and convert protocol buffers\n",
    "\n",
    "Inspired by\n",
    "https://stackoverflow.com/questions/38958751/parsing-nyc-transit-mta-historical-gtfs-data-not-realtime\n",
    "Data Source\n",
    "\n",
    "This extracts data from the protobufs manually downloaded from [MTA Alert Archive](http://web.mta.info/developers/data/archives.html)the latest source suggested at:\n",
    "https://groups.google.com/d/msg/mtadeveloperresources/Whm5XTVINcE/z-LO12ANAAAJ\n",
    "\n",
    "\n",
    "NOTE: This assumes that the protobufs have already been downloaded to <code>MTADelayPredict/data/raw/status</code> e.g. <code>MTADelayPredict/data/raw/status/201901.zip</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '../data/raw/status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-27 23:32:52--  https://developers.google.com/transit/gtfs-realtime/gtfs-realtime.proto\n",
      "Resolving developers.google.com (developers.google.com)... 172.217.10.142, 2607:f8b0:4006:812::200e\n",
      "Connecting to developers.google.com (developers.google.com)|172.217.10.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 27065 (26K) [None]\n",
      "Saving to: ‘../data/raw/status/gtfs-realtime.proto’\n",
      "\n",
      "../data/raw/status/ 100%[===================>]  26.43K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-04-27 23:32:52 (1.89 MB/s) - ‘../data/raw/status/gtfs-realtime.proto’ saved [27065/27065]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proto_file = os.path.join(os.path.join(data_dir), 'gtfs-realtime.proto')\n",
    "! wget -O $proto_file https://developers.google.com/transit/gtfs-realtime/gtfs-realtime.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-27 23:32:53--  https://api.mta.info/nyct-subway.proto.txt\n",
      "Resolving api.mta.info (api.mta.info)... 13.224.215.82, 13.224.215.125, 13.224.215.111, ...\n",
      "Connecting to api.mta.info (api.mta.info)|13.224.215.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5387 (5.3K) [text/plain]\n",
      "Saving to: ‘../data/raw/status/nyct-subway.proto’\n",
      "\n",
      "../data/raw/status/ 100%[===================>]   5.26K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-04-27 23:32:53 (238 MB/s) - ‘../data/raw/status/nyct-subway.proto’ saved [5387/5387]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mta_proto_file = os.path.join(os.path.join(data_dir), 'nyct-subway.proto')\n",
    "! wget -O $mta_proto_file https://api.mta.info/nyct-subway.proto.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING google/protobuf/compiler/parser.cc:637] No syntax specified for the proto file: nyct-subway.proto. Please use 'syntax = \"proto2\";' or 'syntax = \"proto3\";' to specify a syntax version. (Defaulted to proto2 syntax.)\n"
     ]
    }
   ],
   "source": [
    "! protoc -I $data_dir --python_out=$data_dir $data_dir/nyct-subway.proto $data_dir/gtfs-realtime.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data to test parsing\n",
    "\n",
    "Download data as per http://web.mta.info/developers/resources/nyct/MTA-Bus-Time-documentation.htm\n",
    "\n",
    "Unfortunately we have to fetch the minutely ones, as the daily batches no longer seem available\n",
    "\n",
    "These should be fetched using <code>wget https://datamine-history.s3.amazonaws.com/gtfs-2014-09-17-09-31<\\code> for the timestamp of <code>2014-09-17-09-31<\\code>\n",
    "    \n",
    "Historical alert data can be found at: https://m.mymtaalerts.com/archive\n",
    "Realtime service status can be avialable here: http://web.mta.info/status/serviceStatus.txt\n",
    "    \n",
    "Through experimentation, it looks like historical data is only available up until 2018-10-14.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(data_dir))\n",
    "import nyct_subway_pb2\n",
    "import gtfs_realtime_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/raw/status/201811.zip', '../data/raw/status/201812.zip', '../data/raw/status/201901.zip', '../data/raw/status/201902.zip']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "protobuf_paths = glob.glob('{}/[0-9]*.zip'.format(data_dir))\n",
    "\n",
    "if len(protobuf_paths) == 0:\n",
    "    raise ValueError('No matching protbufs found in {}, please download from https://m.mymtaalerts.com/archive')\n",
    "    \n",
    "print(protobuf_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: ../data/raw/status/201811.zip\n",
      "1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A%|                                                         |failures: ------"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fce663dbf00c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import progressbar\n",
    "import io\n",
    "\n",
    "msg = gtfs_realtime_pb2.FeedMessage()\n",
    "\n",
    "# Keep a list of files with failed conversions\n",
    "failed_files = os.path.join(data_dir, 'failures.txt')\n",
    "\n",
    "# unzip monthly rollups, then unzip the daily files inside\n",
    "# This code is largely copied from: https://stackoverflow.com/questions/36285502/how-to-extract-zip-file-recursively-in-python\n",
    "# The daily zipfiles are ~1GB, so there are big speed gains from unzipping in memory\n",
    "for monthly_file in protobuf_paths:\n",
    "    widgets = [progressbar.Percentage(), progressbar.Bar(), progressbar.Variable('failures')]    \n",
    "\n",
    "    \n",
    "    print(\"Extracting: \" + monthly_file)\n",
    "    z = zipfile.ZipFile(monthly_file)\n",
    "    for i,f in enumerate(z.namelist()):\n",
    "        print(\"{}/{}\".format(i+1, len(z.namelist())))\n",
    "        # get directory name from file\n",
    "        dirname = os.path.join(data_dir, os.path.splitext(f)[0])\n",
    "        # create new directory\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        # read inner zip file into bytes buffer \n",
    "        content = io.BytesIO(z.read(f))\n",
    "        zip_file = zipfile.ZipFile(content)\n",
    "        \n",
    "        # Skip if already unzipped\n",
    "        if not force:\n",
    "            if len(glob.glob(dirname+'/*')) == len(zip_file.namelist()):\n",
    "                print(\"Skipping \" + os.path.basename(dirname))\n",
    "                continue\n",
    "         \n",
    "        # Iterate through in-memory zipfile, decoding protobuf into json\n",
    "        bar = progressbar.ProgressBar(widgets=widgets, max_value=len(zip_file.namelist()), min_poll_interval=.5).start()\n",
    "        failures = 0\n",
    "        for j,f2 in enumerate(zip_file.namelist()):\n",
    "            \n",
    "            try:\n",
    "                # Dump the message into a json file for now\n",
    "                msg.ParseFromString(zip_file.read(f2))\n",
    "\n",
    "                # TODO: Do something with the message\n",
    "                \n",
    "            except Exception as e:\n",
    "                # At the moment, some messages a sporadically unable to parse\n",
    "                with io.open(failed_files, 'a') as fh:\n",
    "                    fh.write(f2+'\\n')\n",
    "                    \n",
    "                failures += 1\n",
    "                \n",
    "\n",
    "            sys.stdout.flush()\n",
    "            bar.update(j+1, failures=failures)\n",
    "        zip_file.close()\n",
    "        \n",
    "        bar.finish()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
